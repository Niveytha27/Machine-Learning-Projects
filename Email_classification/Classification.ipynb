{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>email</th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tana.jones@enron.com</td>\n",
       "      <td>alicia.goodrow@enron.com</td>\n",
       "      <td>nice dinner probably knowanyone else anytime w...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>original_message, know, thanks, get, please, m...</td>\n",
       "      <td>['nice', 'dinner', 'probably', 'knowanyone', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sheila Tweed@ECT on 05/15/2001 06</td>\n",
       "      <td>Kay Mann/Corp/Enron@ENRON</td>\n",
       "      <td>absolutely good point peter start draft overri...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7429</td>\n",
       "      <td>please, thanks, enron, need, know, deal, attac...</td>\n",
       "      <td>['absolutely', 'good', 'point', 'peter', 'star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jeff.dasovich@enron.com</td>\n",
       "      <td>christine.piesco@oracle.com</td>\n",
       "      <td>apology schedule melted talked monday swhere f...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>original_message, know, thanks, get, please, m...</td>\n",
       "      <td>['apology', 'schedule', 'melted', 'talked', 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tanya.tamarchenko@enron.com</td>\n",
       "      <td>Richard Lewis/LON/ECT@ECT, James New/LON/ECT@E...</td>\n",
       "      <td>vince uk var breached limit last week uk trade...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>power, market, energy, state, price, californi...</td>\n",
       "      <td>['vince', 'uk', 'var', 'breached', 'limit', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kay.mann@enron.com</td>\n",
       "      <td>Don Hammond/PDX/ECT@ECT, Jody Blackburn/PDX/EC...</td>\n",
       "      <td>problem comment dale_rasmussen ectmann corp en...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6876</td>\n",
       "      <td>please, thanks, enron, need, know, deal, attac...</td>\n",
       "      <td>['problem', 'comment', 'dale_rasmussen', 'ectm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                from  \\\n",
       "0               tana.jones@enron.com   \n",
       "1  Sheila Tweed@ECT on 05/15/2001 06   \n",
       "2            jeff.dasovich@enron.com   \n",
       "3        tanya.tamarchenko@enron.com   \n",
       "4                 kay.mann@enron.com   \n",
       "\n",
       "                                                  to  \\\n",
       "0                           alicia.goodrow@enron.com   \n",
       "1                          Kay Mann/Corp/Enron@ENRON   \n",
       "2                        christine.piesco@oracle.com   \n",
       "3  Richard Lewis/LON/ECT@ECT, James New/LON/ECT@E...   \n",
       "4  Don Hammond/PDX/ECT@ECT, Jody Blackburn/PDX/EC...   \n",
       "\n",
       "                                               email  Document_No  \\\n",
       "0  nice dinner probably knowanyone else anytime w...            0   \n",
       "1  absolutely good point peter start draft overri...            1   \n",
       "2  apology schedule melted talked monday swhere f...            2   \n",
       "3  vince uk var breached limit last week uk trade...            3   \n",
       "4  problem comment dale_rasmussen ectmann corp en...            4   \n",
       "\n",
       "   Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0             2.0              0.9333   \n",
       "1             3.0              0.7429   \n",
       "2             2.0              0.6207   \n",
       "3             1.0              0.6694   \n",
       "4             3.0              0.6876   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  original_message, know, thanks, get, please, m...   \n",
       "1  please, thanks, enron, need, know, deal, attac...   \n",
       "2  original_message, know, thanks, get, please, m...   \n",
       "3  power, market, energy, state, price, californi...   \n",
       "4  please, thanks, enron, need, know, deal, attac...   \n",
       "\n",
       "                                                Text  \n",
       "0  ['nice', 'dinner', 'probably', 'knowanyone', '...  \n",
       "1  ['absolutely', 'good', 'point', 'peter', 'star...  \n",
       "2  ['apology', 'schedule', 'melted', 'talked', 'm...  \n",
       "3  ['vince', 'uk', 'var', 'breached', 'limit', 'l...  \n",
       "4  ['problem', 'comment', 'dale_rasmussen', 'ectm...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('email_df_final.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  3.,  1.,  8., 11., 14.,  5., 13.,  0., 10.,  4.,  9.,  7.,\n",
       "        6., 12.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Dominant_Topic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9770 entries, 0 to 10347\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   from                9770 non-null   object \n",
      " 1   to                  9770 non-null   object \n",
      " 2   email               9770 non-null   object \n",
      " 3   Document_No         9770 non-null   int64  \n",
      " 4   Dominant_Topic      9770 non-null   float64\n",
      " 5   Topic_Perc_Contrib  9770 non-null   float64\n",
      " 6   Keywords            9770 non-null   object \n",
      " 7   Text                9770 non-null   object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 687.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.email\n",
    "y=data.Dominant_Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        nice dinner probably knowanyone else anytime w...\n",
       "1        absolutely good point peter start draft overri...\n",
       "2        apology schedule melted talked monday swhere f...\n",
       "3        vince uk var breached limit last week uk trade...\n",
       "4        problem comment dale_rasmussen ectmann corp en...\n",
       "                               ...                        \n",
       "10343    attached redline change discussed please revie...\n",
       "10344    review forwarded corp enron anila hoxhaattache...\n",
       "10345    hi jerry final execution version letter agreem...\n",
       "10346    richard_shapiro enron com david_parquet enron ...\n",
       "10347    better original_message original_message fyi d...\n",
       "Name: email, Length: 9770, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  3.,  1.,  8., 11., 14.,  5., 13.,  0., 10.,  4.,  9.,  7.,\n",
       "        6., 12.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7816"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1954"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7816"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1954"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfv = TfidfVectorizer(stop_words='english',\n",
    "                        sublinear_tf=True,\n",
    "                        smooth_idf=True,\n",
    "                        analyzer='word',\n",
    "                        min_df=10,\n",
    "                        max_df=0.95,\n",
    "                        max_features=30000)\n",
    "X_train = tfv.fit_transform(X_train)\n",
    "X_test = tfv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=250)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=250)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3   0   0   1   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  5 131  15  83   0   0   0   0   0   0   1   4   0   0   1]\n",
      " [  6   3 268  78   0   0   0   0   2   0   0   4   0   0   1]\n",
      " [  9  12  34 466   0   1   0   0   1   0   0   9   0   6   1]\n",
      " [  1   0   0   0   3   0   0   0   0   0   0   0   0   0   0]\n",
      " [  3  14  10  41   0  20   0   0   0   0   0   0   0   1   1]\n",
      " [  1   1   0   0   0   0   2   0   1   0   0   5   0   0   0]\n",
      " [  1   0   2   7   0   0   0   8   1   0   0   0   0   0   0]\n",
      " [  1   6  21  29   0   0   1   0  92   0   1   5   0   0   5]\n",
      " [  1   0   0   4   0   0   0   0   5   4   0   0   0   0   0]\n",
      " [  0  10   4   8   0   0   0   0   3   0  27   1   0   0   0]\n",
      " [  0   8   7   8   0   0   0   0   0   0   0 259   0   2   0]\n",
      " [  0   1   2   2   0   0   0   0   0   0   0   0   3   0   0]\n",
      " [  1   3   0  10   0   0   0   0   0   0   0   7   1  50   0]\n",
      " [  5   2  41  13   0   0   0   0   2   0   0   2   0   1  28]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6980552712384852"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred_rfc)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='rbf',random_state=0)\n",
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3   0   0   1   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 161  16  57   0   0   0   0   2   0   1   2   0   0   1]\n",
      " [  0   2 311  45   0   0   0   0   1   0   0   2   0   0   1]\n",
      " [  0   8  28 487   0   0   0   0   1   0   0   6   0   9   0]\n",
      " [  0   0   0   1   3   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   9  14  45   0  19   0   0   1   0   0   0   0   1   0]\n",
      " [  0   0   1   1   0   0   3   0   2   0   0   3   0   0   0]\n",
      " [  0   0   1   9   0   0   0   8   1   0   0   0   0   0   0]\n",
      " [  0   1  14  17   0   0   0   0 120   0   1   5   0   0   3]\n",
      " [  0   0   0   5   0   0   0   0   4   5   0   0   0   0   0]\n",
      " [  0   3   4   9   0   0   0   0   3   0  34   0   0   0   0]\n",
      " [  0   8   4  12   0   0   0   0   0   0   0 256   0   2   2]\n",
      " [  0   0   3   2   0   0   0   0   0   0   0   0   3   0   0]\n",
      " [  0   0   2  14   0   0   0   0   0   0   0   3   1  52   0]\n",
      " [  0   1  38   7   0   0   0   0   3   0   0   1   0   1  43]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7717502558853634"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred_svc)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
