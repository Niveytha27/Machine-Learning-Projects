{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of emails - supervised model\n",
    "\n",
    "Using the output dataset from topic modelling which contains dominant topic for each email text, taking it as a supervised classfication model dataset, need to create a classfication model to predict the topic for new emails.\n",
    "\n",
    "I am taking email text column which will be converted to matrix using Tf-idf vectorizer as a feature and Dominant topic as a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>email</th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tana.jones@enron.com</td>\n",
       "      <td>alicia.goodrow@enron.com</td>\n",
       "      <td>nice dinner probably knowanyone else anytime w...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>original_message, know, thanks, get, please, m...</td>\n",
       "      <td>['nice', 'dinner', 'probably', 'knowanyone', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sheila Tweed@ECT on 05/15/2001 06</td>\n",
       "      <td>Kay Mann/Corp/Enron@ENRON</td>\n",
       "      <td>absolutely good point peter start draft overri...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7429</td>\n",
       "      <td>please, thanks, enron, need, know, deal, attac...</td>\n",
       "      <td>['absolutely', 'good', 'point', 'peter', 'star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jeff.dasovich@enron.com</td>\n",
       "      <td>christine.piesco@oracle.com</td>\n",
       "      <td>apology schedule melted talked monday swhere f...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>original_message, know, thanks, get, please, m...</td>\n",
       "      <td>['apology', 'schedule', 'melted', 'talked', 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tanya.tamarchenko@enron.com</td>\n",
       "      <td>Richard Lewis/LON/ECT@ECT, James New/LON/ECT@E...</td>\n",
       "      <td>vince uk var breached limit last week uk trade...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>power, market, energy, state, price, californi...</td>\n",
       "      <td>['vince', 'uk', 'var', 'breached', 'limit', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kay.mann@enron.com</td>\n",
       "      <td>Don Hammond/PDX/ECT@ECT, Jody Blackburn/PDX/EC...</td>\n",
       "      <td>problem comment dale_rasmussen ectmann corp en...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6876</td>\n",
       "      <td>please, thanks, enron, need, know, deal, attac...</td>\n",
       "      <td>['problem', 'comment', 'dale_rasmussen', 'ectm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                from  \\\n",
       "0               tana.jones@enron.com   \n",
       "1  Sheila Tweed@ECT on 05/15/2001 06   \n",
       "2            jeff.dasovich@enron.com   \n",
       "3        tanya.tamarchenko@enron.com   \n",
       "4                 kay.mann@enron.com   \n",
       "\n",
       "                                                  to  \\\n",
       "0                           alicia.goodrow@enron.com   \n",
       "1                          Kay Mann/Corp/Enron@ENRON   \n",
       "2                        christine.piesco@oracle.com   \n",
       "3  Richard Lewis/LON/ECT@ECT, James New/LON/ECT@E...   \n",
       "4  Don Hammond/PDX/ECT@ECT, Jody Blackburn/PDX/EC...   \n",
       "\n",
       "                                               email  Document_No  \\\n",
       "0  nice dinner probably knowanyone else anytime w...            0   \n",
       "1  absolutely good point peter start draft overri...            1   \n",
       "2  apology schedule melted talked monday swhere f...            2   \n",
       "3  vince uk var breached limit last week uk trade...            3   \n",
       "4  problem comment dale_rasmussen ectmann corp en...            4   \n",
       "\n",
       "   Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0             2.0              0.9333   \n",
       "1             3.0              0.7429   \n",
       "2             2.0              0.6207   \n",
       "3             1.0              0.6694   \n",
       "4             3.0              0.6876   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  original_message, know, thanks, get, please, m...   \n",
       "1  please, thanks, enron, need, know, deal, attac...   \n",
       "2  original_message, know, thanks, get, please, m...   \n",
       "3  power, market, energy, state, price, californi...   \n",
       "4  please, thanks, enron, need, know, deal, attac...   \n",
       "\n",
       "                                                Text  \n",
       "0  ['nice', 'dinner', 'probably', 'knowanyone', '...  \n",
       "1  ['absolutely', 'good', 'point', 'peter', 'star...  \n",
       "2  ['apology', 'schedule', 'melted', 'talked', 'm...  \n",
       "3  ['vince', 'uk', 'var', 'breached', 'limit', 'l...  \n",
       "4  ['problem', 'comment', 'dale_rasmussen', 'ectm...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('email_df_final.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  3.,  1.,  8., 11., 14.,  5., 13.,  0., 10.,  4.,  9.,  7.,\n",
       "        6., 12.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Dominant_Topic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9770 entries, 0 to 10347\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   from                9770 non-null   object \n",
      " 1   to                  9770 non-null   object \n",
      " 2   email               9770 non-null   object \n",
      " 3   Document_No         9770 non-null   int64  \n",
      " 4   Dominant_Topic      9770 non-null   float64\n",
      " 5   Topic_Perc_Contrib  9770 non-null   float64\n",
      " 6   Keywords            9770 non-null   object \n",
      " 7   Text                9770 non-null   object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 687.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.email\n",
    "y=data.Dominant_Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        nice dinner probably knowanyone else anytime w...\n",
       "1        absolutely good point peter start draft overri...\n",
       "2        apology schedule melted talked monday swhere f...\n",
       "3        vince uk var breached limit last week uk trade...\n",
       "4        problem comment dale_rasmussen ectmann corp en...\n",
       "                               ...                        \n",
       "10343    attached redline change discussed please revie...\n",
       "10344    review forwarded corp enron anila hoxhaattache...\n",
       "10345    hi jerry final execution version letter agreem...\n",
       "10346    richard_shapiro enron com david_parquet enron ...\n",
       "10347    better original_message original_message fyi d...\n",
       "Name: email, Length: 9770, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  3.,  1.,  8., 11., 14.,  5., 13.,  0., 10.,  4.,  9.,  7.,\n",
       "        6., 12.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf-idf vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfv = TfidfVectorizer(stop_words='english',\n",
    "                        sublinear_tf=True,\n",
    "                        smooth_idf=True,\n",
    "                        analyzer='word',\n",
    "                        min_df=10,\n",
    "                        max_df=0.95,\n",
    "                        max_features=30000)\n",
    "X_train = tfv.fit_transform(X_train)\n",
    "X_test = tfv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_estimators=250)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=250,class_weight='balanced')\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "y_pred_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3   0   0   1   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  8 114  17  94   0   0   1   0   1   0   1   3   0   0   1]\n",
      " [ 13   2 264  77   0   0   0   0   1   0   0   5   0   0   0]\n",
      " [ 11   8  36 461   0   1   0   0   1   0   0   8   1  12   0]\n",
      " [  1   0   0   0   3   0   0   0   0   0   0   0   0   0   0]\n",
      " [  6   9   8  42   0  25   0   0   0   0   0   0   0   0   0]\n",
      " [  1   1   1   0   0   0   2   0   0   0   0   5   0   0   0]\n",
      " [  1   1   0   8   0   0   0   8   0   1   0   0   0   0   0]\n",
      " [  5   7  19  35   2   0   0   0  83   0   1   6   0   0   3]\n",
      " [  1   0   1   4   0   0   0   0   1   7   0   0   0   0   0]\n",
      " [  2   6   1  12   0   0   0   0   0   0  30   2   0   0   0]\n",
      " [  0   7   7   9   0   0   0   0   0   0   1 255   0   3   2]\n",
      " [  0   0   1   1   0   0   0   0   0   0   0   1   5   0   0]\n",
      " [  1   2   0  10   0   0   0   0   0   0   0   3   1  55   0]\n",
      " [  7   3  45   9   0   0   0   0   2   0   0   1   0   1  26]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "cm = confusion_matrix(y_test, y_pred_rfc)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6809468136541"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1_score\n",
    "f1_score(y_test, y_pred_rfc,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced', random_state=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='rbf',random_state=0,class_weight='balanced')\n",
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "y_pred_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3   0   0   1   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 168  15  44   0   0   0   0   3   0   2   4   0   1   3]\n",
      " [  0   2 303  37   0   1   0   0   1   0   0   4   0   0  14]\n",
      " [  0  17  35 455   0   1   0   1   3   0   0   9   2  16   0]\n",
      " [  0   0   0   1   3   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   9  10  26   0  39   0   0   1   0   2   0   0   1   1]\n",
      " [  0   0   0   0   0   0   4   0   1   0   0   2   0   0   3]\n",
      " [  0   0   0   5   0   0   0  12   1   0   0   0   0   0   1]\n",
      " [  0   2  12  12   0   0   0   0 125   0   2   4   0   0   4]\n",
      " [  0   0   2   2   0   0   0   0   4   6   0   0   0   0   0]\n",
      " [  0   1   5   5   0   0   0   0   4   0  38   0   0   0   0]\n",
      " [  0   7   3   8   0   0   0   0   0   0   1 260   0   3   2]\n",
      " [  0   0   2   0   0   0   0   0   0   0   0   0   6   0   0]\n",
      " [  0   0   2   6   0   0   0   0   0   0   0   3   1  60   0]\n",
      " [  0   1  16   3   0   0   0   0   2   0   0   1   0   1  70]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "cm = confusion_matrix(y_test, y_pred_svc)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7907425544422999"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1_score\n",
    "f1_score(y_test, y_pred_svc,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector classifier gives much better classification results than Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
